{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First protocol\n",
    "_Code written and runs in python 3.11.0. Progresses from top to botttom. Go to bottom and run all for proper use. Modify environment variables and queries as needed._  \n",
    "_Markdown cells will highlight functionality of following code cell. Functionality will be derived from the list below with the numbered list being referenced in markdown cells._\n",
    "\n",
    "## Protocol\n",
    "· Start with keywords:\n",
    "\n",
    "- Smartchain\n",
    "\n",
    "- Nft\n",
    "\n",
    "- Airdrop\n",
    "\n",
    "- Crypto\n",
    "\n",
    "- …etc.\n",
    "\n",
    "1. Sample up to 10k tweets containing at least one term from 100 random hours from the past year (so 1M tweets)\n",
    "\n",
    "2. Determine the most engaged (top) with users from this combined sample (100 or 1000)\n",
    "\n",
    "3. Pull up to 1000 comments for each top user\n",
    "\n",
    "4. Determine top users whose comments mention at least three users other than the top user\n",
    "\n",
    "5. Expand top user sample if we don’t have at least 100 airdrop seeders\n",
    "\n",
    "6. Time series chart plots:\n",
    "\n",
    "7. Top user activity\n",
    "\n",
    "8. Airdrop seeder activity\n",
    "\n",
    "9. Negative reaction activity? (based on sentiment analysis of replies to airdrop messages)\n",
    "\n",
    "10. External crypto value signals (from where?)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies\n",
    "Run the following commands in the terminal to install the required packages\n",
    "\n",
    "$pip install requests  \n",
    "$pip install pandas  \n",
    "$pip install datetime  \n",
    "$pip install python-dateutil\n",
    "\n",
    "--------------------  \n",
    "create two files <data.json> and <data.csv> in the same folder as this jupyter notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Authentication step\n",
    "In the code cell below replace bearer_token with your bearer token. Run the cell, then delete your bearer token.\n",
    "This creates the token as an environment variable to be used under the name TOKEN. The token can then be removed so that others do not have access to your token when code is shared via GitHub. I will change this to dotenv and a .gitignore file later I just havent done that yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TOKEN'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"This cell creates functions to be used for authentication as well as creating endpoints.\"\"\"\n",
    "import requests\n",
    "\n",
    "def auth():\n",
    "    \"\"\"Retrieves your bearer token.\"\"\"\n",
    "    return os.getenv('TOKEN')\n",
    "\n",
    "def create_headers(bearer_token):\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "\n",
    "\n",
    "def create_url(keyword, start_date, end_date, max_results = 10):\n",
    "    \n",
    "    #Change to the endpoint you want to collect data from\n",
    "    search_url = \"https://api.twitter.com/2/tweets/search/recent\" \n",
    "\n",
    "    #change params based on the endpoint you are using\n",
    "    query_params = {'query': keyword,\n",
    "                    'start_time': start_date,\n",
    "                    'end_time': end_date,\n",
    "                    'max_results': max_results,\n",
    "                    'expansions': 'author_id',\n",
    "                    'tweet.fields': 'id,text,author_id,public_metrics',\n",
    "                    'user.fields': 'id,name,username,created_at',\n",
    "                    #'place.fields': 'country',\n",
    "                    'next_token': {}}\n",
    "    return (search_url, query_params)\n",
    "\n",
    "def connect_to_endpoint(url, headers, params, next_token = None):\n",
    "    params['next_token'] = next_token   #params object received from create_url function\n",
    "    response = requests.request(\"GET\", url, headers = headers, params = params)\n",
    "    print(\"Endpoint Response Code: \" + str(response.status_code))\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n",
    "\n",
    "print(auth())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import random\n",
    "\"\"\"This code cell contains two functions (is_leap_year and random_date) which help generate a random one hour date range when random_date() is called\"\"\"\n",
    "# Use by calling \"start_time, end_time = random_date()\"\n",
    "\n",
    "def is_leap_year(year):\n",
    "    \"\"\"Returns True if the given year is a leap year, False otherwise.\"\"\"\n",
    "    if year % 4 == 0:\n",
    "        if year % 100 == 0:\n",
    "            if year % 400 == 0:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        else:\n",
    "            return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def random_date():\n",
    "    \"\"\"Generate a random one hour date range within the last year in RFC 3339 format to be used with twitter API.\"\"\"\n",
    "    year = random.randint(datetime.datetime.now().year - 1, datetime.datetime.now().year)\n",
    "    month = random.randint(1, datetime.datetime.now().month)\n",
    "    if month == datetime.datetime.now().month:\n",
    "        day = random.randint(1, datetime.datetime.now().day - 1)\n",
    "    elif month == 2:\n",
    "        if is_leap_year(year):\n",
    "            day = random.randint(1, 29)\n",
    "        else:\n",
    "            day = random.randint(1, 28)\n",
    "    elif month in [1, 3, 5, 7, 8, 10, 12]:\n",
    "        day = random.randint(1, 31)\n",
    "    else:\n",
    "        day = random.randint(1, 31)\n",
    "    hour = random.randint(0, 23)\n",
    "    start_time = datetime.datetime(year, month, day, hour)\n",
    "    end_time = start_time + datetime.timedelta(hours=1)\n",
    "    start_timestamp = start_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    end_timestamp = end_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    return start_timestamp, end_timestamp\n",
    "\n",
    "#start_time1, end_time1 = random_date()\n",
    "#print(f\"The one hour range is from {start_time1} to {end_time1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Creates a function called write_to_csv which allows for writing a json file to a csv file.\"\"\"\n",
    "import json\n",
    "import csv\n",
    " \n",
    "\n",
    "def write_to_csv():\n",
    "    # Opening JSON file and loading the data\n",
    "    # into the variable data\n",
    "    with open('data.json') as json_file:\n",
    "        data = json.load(json_file)\n",
    " \n",
    "    tweet_data = data['data']\n",
    " \n",
    "    # now we will open a file for writing\n",
    "    data_file = open('data.csv', 'w')\n",
    " \n",
    "    # create the csv writer object\n",
    "    csv_writer = csv.writer(data_file)\n",
    " \n",
    "    # Counter variable used for writing\n",
    "    # headers to the CSV file\n",
    "    count = 0\n",
    " \n",
    "    for head in tweet_data:\n",
    "        if count == 0:\n",
    " \n",
    "            # Writing headers of CSV file\n",
    "            header = head.keys()\n",
    "            csv_writer.writerow(header)\n",
    "            count += 1\n",
    " \n",
    "        # Writing data of CSV file\n",
    "        csv_writer.writerow(head.values())\n",
    " \n",
    "    data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test list until i get full access endpoint and can use the random generated hour ranges.\n",
    "start_list = [\"2023-01-08T17:00:00Z\", \"2023-01-10T17:00:00Z\", \"2023-01-11T17:00:00Z\"]\n",
    "end_list = [\"2023-01-08T18:00:00Z\", \"2023-01-10T18:00:00Z\", \"2023-01-11T18:00:00Z\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "\n",
    "\n",
    "def tweets_per_hour_range(keyword: str):\n",
    "    \"\"\"This function returns 10,000 tweets (containing keyword) per 1 hour range from 100 random hour ranges in the past year.\"\"\"\n",
    "    bearer_token = auth()\n",
    "    headers = create_headers(bearer_token)\n",
    "    # Creates 100 random one hour ranges in the past year\n",
    "    \"\"\"\n",
    "    start_list = list()\n",
    "    end_list = list()\n",
    "    for _ in range(0, 100):\n",
    "        start_time, end_time = random_date()\n",
    "        while start_time in start_list:\n",
    "            start_time, end_time = random_date()\n",
    "        start_list.append(start_time)\n",
    "        end_list.append(end_time)\n",
    "    \"\"\"\n",
    "\n",
    "    total_tweets: int = 0\n",
    "    max_results: int = 100\n",
    "\n",
    "    # Create file data.csv\n",
    "    csvFile = open(\"data.csv\", \"a\", newline=\"\", encoding='utf-8')\n",
    "    csvWriter = csv.writer(csvFile)\n",
    "\n",
    "    #Create headers for the data you want to save, in this example, we only want save these columns in our dataset\n",
    "    csvWriter.writerow(['author id', 'created_at', 'id', 'like_count', 'reply_count','retweet_count', 'source', 'tweet'])\n",
    "    csvFile.close()\n",
    "\n",
    "    for i in range(0,len(start_list)):\n",
    "\n",
    "        # Inputs\n",
    "        count: int = 0 # Counting tweets per time period\n",
    "        max_count: int = 400 # Max tweets per time period\n",
    "        flag: bool = True\n",
    "        next_token: str = None\n",
    "    \n",
    "        # Check if flag is true\n",
    "        while flag:\n",
    "            # Check if max_count reached\n",
    "            if count >= max_count:\n",
    "                break\n",
    "            print(\"-------------------\")\n",
    "            print(\"Token: \", next_token)\n",
    "            url = create_url(keyword, start_list[i],end_list[i], max_results)\n",
    "            json_response = connect_to_endpoint(url[0], headers, url[1], next_token)\n",
    "            result_count = json_response['meta']['result_count']\n",
    "\n",
    "            if 'next_token' in json_response['meta']:\n",
    "                # Save the token to use for next call\n",
    "                next_token = json_response['meta']['next_token']\n",
    "                print(\"Next Token: \", next_token)\n",
    "                if result_count is not None and result_count > 0 and next_token is not None:\n",
    "                    print(\"Start Date: \", start_list[i])\n",
    "                    write_to_csv(json_response, \"data.csv\")\n",
    "                    count += result_count\n",
    "                    total_tweets += result_count\n",
    "                    print(\"Total # of Tweets added: \", total_tweets)\n",
    "                    print(\"-------------------\")\n",
    "                    time.sleep(5)                \n",
    "            # If no next token exists\n",
    "            else:\n",
    "                if result_count is not None and result_count > 0:\n",
    "                    print(\"-------------------\")\n",
    "                    print(\"Start Date: \", start_list[i])\n",
    "                    write_to_csv(json_response, \"data.csv\")\n",
    "                    count += result_count\n",
    "                    total_tweets += result_count\n",
    "                    print(\"Total # of Tweets added: \", total_tweets)\n",
    "                    print(\"-------------------\")\n",
    "                    time.sleep(5)\n",
    "            \n",
    "                #Since this is the final request, turn flag to false to move to the next time period.\n",
    "                flag = False\n",
    "                next_token = None\n",
    "            time.sleep(5)\n",
    "    print(\"Total number of results: \", total_tweets)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Working Cell\n",
    "\n",
    "The below cell is intended to be the final cell which ties together all functions into the 'solution' to the protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fqk406o5tclcda1x6vzad62syn575p\n",
      "Start Date:  2023-01-08T17:00:00Z\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "write_to_csv() takes 0 positional arguments but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [66], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcsv\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m tweets_per_hour_range(\u001b[39m\"\u001b[39;49m\u001b[39mSmartchain OR Airdrop OR Crypto\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn [65], line 57\u001b[0m, in \u001b[0;36mtweets_per_hour_range\u001b[0;34m(keyword)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mif\u001b[39;00m result_count \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m result_count \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m next_token \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     56\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mStart Date: \u001b[39m\u001b[39m\"\u001b[39m, start_list[i])\n\u001b[0;32m---> 57\u001b[0m     write_to_csv(json_response, \u001b[39m\"\u001b[39;49m\u001b[39mdata.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     58\u001b[0m     count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m result_count\n\u001b[1;32m     59\u001b[0m     total_tweets \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m result_count\n",
      "\u001b[0;31mTypeError\u001b[0m: write_to_csv() takes 0 positional arguments but 2 were given"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "tweets_per_hour_range(\"Smartchain OR Airdrop OR Crypto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Response Code: 400\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "(400, '{\"errors\":[{\"parameters\":{\"max_results\":[\"1000\"]},\"message\":\"The `max_results` query parameter value [1000] is not between 10 and 100\"}],\"title\":\"Invalid Request\",\"detail\":\"One or more parameters to your request was invalid.\",\"type\":\"https://api.twitter.com/2/problems/invalid-request\"}')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [45], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m max_results \u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m\n\u001b[1;32m     16\u001b[0m url \u001b[39m=\u001b[39m create_url(keyword, start_time, end_time, max_results)\n\u001b[0;32m---> 17\u001b[0m json_response \u001b[39m=\u001b[39m connect_to_endpoint(url[\u001b[39m0\u001b[39;49m], headers, url[\u001b[39m1\u001b[39;49m])\n\u001b[1;32m     18\u001b[0m result_dict \u001b[39m=\u001b[39m json_response[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     19\u001b[0m \u001b[39m#while \"next_token\" in json_response[\"meta\"] and len(result_dict) < 9900:\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[39m#print(json.dumps(json_response, indent=4, sort_keys=True))\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     \u001b[39m#json_response = connect_to_endpoint(url[0], headers, url[1], json_response[\"meta\"][\"next_token\"])\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[39m#result_dict.extend(json_response[\"data\"])\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[39m#print(json.dumps(json_response, indent=4, sort_keys=True))\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [37], line 35\u001b[0m, in \u001b[0;36mconnect_to_endpoint\u001b[0;34m(url, headers, params, next_token)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEndpoint Response Code: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(response\u001b[39m.\u001b[39mstatus_code))\n\u001b[1;32m     34\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m!=\u001b[39m \u001b[39m200\u001b[39m:\n\u001b[0;32m---> 35\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(response\u001b[39m.\u001b[39mstatus_code, response\u001b[39m.\u001b[39mtext)\n\u001b[1;32m     36\u001b[0m \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mjson()\n",
      "\u001b[0;31mException\u001b[0m: (400, '{\"errors\":[{\"parameters\":{\"max_results\":[\"1000\"]},\"message\":\"The `max_results` query parameter value [1000] is not between 10 and 100\"}],\"title\":\"Invalid Request\",\"detail\":\"One or more parameters to your request was invalid.\",\"type\":\"https://api.twitter.com/2/problems/invalid-request\"}')"
     ]
    }
   ],
   "source": [
    "\"\"\"WORKING EXAMPLE OF SO FAR, Above is for more function use etc.\"\"\"\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "bearer_token = auth()\n",
    "\"\"\"input the necessary inputs below.\"\"\"\n",
    "headers = create_headers(bearer_token)\n",
    "keyword = \"Smartchain OR Airdrop OR Crypto\"\n",
    "# Use the commented out code below when using full access api\n",
    "#start_time, end_time = random_date()\n",
    "start_time = \"2023-01-02T17:00:00Z\"\n",
    "end_time = \"2023-01-04T20:00:00Z\"\n",
    "\n",
    "max_results = 100\n",
    "url = create_url(keyword, start_time, end_time, max_results)\n",
    "json_response = connect_to_endpoint(url[0], headers, url[1])\n",
    "result_dict = json_response[\"data\"]\n",
    "#while \"next_token\" in json_response[\"meta\"] and len(result_dict) < 9900:\n",
    "    #print(json.dumps(json_response, indent=4, sort_keys=True))\n",
    "    #json_response = connect_to_endpoint(url[0], headers, url[1], json_response[\"meta\"][\"next_token\"])\n",
    "    #result_dict.extend(json_response[\"data\"])\n",
    "#print(json.dumps(json_response, indent=4, sort_keys=True))\n",
    "print(json.dumps(result_dict, indent=4, sort_keys=True))\n",
    "\n",
    "#def append_to_csv(json_response, fileName):\n",
    "with open('data.json', 'w') as f:\n",
    "    json.dump(json_response, f)\n",
    "#df = pd.read_json('data.json')\n",
    "write_to_csv()\n",
    "#url = create_url(keyword, start_time, end_time, max_results)\n",
    "#json_response = connect_to_endpoint(url[0], headers, url[1])\n",
    "#print(json.dumps(json_response, indent=4, sort_keys=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
