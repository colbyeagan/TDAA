{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First protocol\n",
    "_Code written and runs in python 3.11.0. Modify environment variables and queries as needed._  \n",
    "_Please use venv_\n",
    "\n",
    "## Protocol\n",
    "· Start with keywords:\n",
    "\n",
    "- Smartchain\n",
    "\n",
    "- Nft\n",
    "\n",
    "- Airdrop\n",
    "\n",
    "- Crypto\n",
    "\n",
    "- …etc.\n",
    "\n",
    "1. Sample up to 10k tweets containing at least one term from 100 random hours from the past year (so 1M tweets)\n",
    "\n",
    "2. Determine the most engaged (top) with users from this combined sample (100 or 1000)\n",
    "\n",
    "3. Pull up to 1000 comments for each top user\n",
    "\n",
    "4. Determine top users whose comments mention at least three users other than the top user\n",
    "\n",
    "5. Expand top user sample if we don’t have at least 100 airdrop seeders\n",
    "\n",
    "6. Time series chart plots:\n",
    "\n",
    "7. Top user activity\n",
    "\n",
    "8. Airdrop seeder activity\n",
    "\n",
    "9. Negative reaction activity? (based on sentiment analysis of replies to airdrop messages)\n",
    "\n",
    "10. External crypto value signals (from where?)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies\n",
    "Run the following commands in the terminal to install the required packages\n",
    "\n",
    "$pip install requests  \n",
    "  \n",
    "$pip install pandas  \n",
    "  \n",
    "$pip install datetime  \n",
    "  \n",
    "$pip install python-dateutil\n",
    "  \n",
    "\n",
    "--------------------  \n",
    "create a files <data.json> in the same folder as this jupyter notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Authentication step\n",
    "In the code cell below replace bearer_token with your bearer token. Run the cell, then delete your bearer token.\n",
    "This creates the token as an environment variable to be used under the name TOKEN. The token can then be removed so that others do not have access to your token when code is shared via GitHub. I will change this to dotenv and a .gitignore file later I just havent done that yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TOKEN'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This cell creates functions to be used for authentication as well as creating endpoints.\"\"\"\n",
    "import requests\n",
    "\n",
    "def auth():\n",
    "    \"\"\"Retrieves your bearer token.\"\"\"\n",
    "    return os.getenv('TOKEN')\n",
    "\n",
    "def create_headers(bearer_token):\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "\n",
    "\n",
    "def create_full_search_url(keyword: str, start_date: list[str], end_date: list[str], max_results: int = 100):\n",
    "    \n",
    "    search_url: str = \"https://api.twitter.com/2/tweets/search/all\" \n",
    "\n",
    "    #change params based on the endpoint you are using\n",
    "    query_params = {'query': keyword,\n",
    "                    'start_time': start_date,\n",
    "                    'end_time': end_date,\n",
    "                    'max_results': max_results,\n",
    "                    'expansions': 'referenced_tweets.id.author_id',\n",
    "                    'tweet.fields': 'id,author_id,conversation_id,created_at,in_reply_to_user_id,lang,public_metrics,referenced_tweets,source,text',\n",
    "                    #'user.fields': 'id,name,public_metrics,username,verified',\n",
    "                    #'place.fields': 'country',\n",
    "                    'next_token': {}}\n",
    "    return (search_url, query_params)\n",
    "\n",
    "def search_retweet_id_url(id: str):\n",
    "    \n",
    "    search_url: str = f\"https://api.twitter.com/2/tweets/{id}\" \n",
    "\n",
    "    #change params based on the endpoint you are using\n",
    "    query_params = {'tweet.fields': 'author_id'}\n",
    "    return (search_url, query_params)\n",
    "\n",
    "def connect_to_endpoint(url, headers, params, next_token = None):\n",
    "    params['next_token'] = next_token   #params object received from create_url function\n",
    "    response = requests.request(\"GET\", url, headers = headers, params = params)\n",
    "    print(\"\\nEndpoint Response Code: \" + str(response.status_code))\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n",
    "\n",
    "#print(auth())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import random\n",
    "\"\"\"This code cell contains two functions (is_leap_year and random_date) which help generate a random one hour date range when random_date() is called\"\"\"\n",
    "# Use by calling \"start_time, end_time = random_date()\"\n",
    "\n",
    "def is_leap_year(year):\n",
    "    \"\"\"Returns True if the given year is a leap year, False otherwise.\"\"\"\n",
    "    if year % 4 == 0:\n",
    "        if year % 100 == 0:\n",
    "            if year % 400 == 0:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        else:\n",
    "            return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def sort_timestamps(timestamps):\n",
    "    # Convert timestamps to datetime objects\n",
    "    datetimes = [datetime.datetime.fromisoformat(ts) for ts in timestamps]\n",
    "    # Sort datetime objects\n",
    "    datetimes.sort()\n",
    "    # Convert sorted datetime objects back to timestamps\n",
    "    sorted_timestamps = [dt.strftime(\"%Y-%m-%dT%H:%M:%SZ\") for dt in datetimes]\n",
    "    return sorted_timestamps\n",
    "\n",
    "def random_date():\n",
    "    \"\"\"Generate a random one hour date range within the last year in RFC 3339 format to be used with twitter API.\"\"\"\n",
    "    month = random.randint(1, 12)\n",
    "    year = random.randint(datetime.datetime.now().year - 1, datetime.datetime.now().year)\n",
    "    if month <= datetime.datetime.now().month:\n",
    "        year = datetime.datetime.now().year\n",
    "    else:\n",
    "        year = datetime.datetime.now().year - 1\n",
    "    if month == datetime.datetime.now().month:\n",
    "        day = random.randint(1, datetime.datetime.now().day - 1)\n",
    "    elif month == 2:\n",
    "        if is_leap_year(year):\n",
    "            day = random.randint(1, 29)\n",
    "        else:\n",
    "            day = random.randint(1, 28)\n",
    "    elif month in [1, 3, 5, 7, 8, 10, 12]:\n",
    "        day = random.randint(1, 31)\n",
    "    else:\n",
    "        day = random.randint(1, 30)\n",
    "    hour = random.randint(0, 23)\n",
    "    start_time = datetime.datetime(year, month, day, hour)\n",
    "    end_time = start_time + datetime.timedelta(hours=1)\n",
    "    start_timestamp = start_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    end_timestamp = end_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    return start_timestamp, end_timestamp\n",
    "\n",
    "def return_n_random_hour_ranges_sorted(n: int) -> list:\n",
    "    start_time1_list = list()\n",
    "    end_time1_list = list()\n",
    "    for i in range(0, n):\n",
    "        s1, s2 = random_date()\n",
    "        while s1 in start_time1_list:\n",
    "            s1, s2 = random_date()\n",
    "        start_time1_list.append(s1)\n",
    "        end_time1_list.append(s2)\n",
    "\n",
    "    sorted_start = sort_timestamps(start_time1_list)\n",
    "    sorted_end = sort_timestamps(end_time1_list)\n",
    "    return (sorted_start, sorted_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"WORKING EXAMPLE OF SO FAR, Above is for more function use etc.\"\"\"\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "from typing import Optional\n",
    "import time\n",
    "\n",
    "def tweets_per_range(keyword: str, start_times_list: list, end_times_list: list, results_per_range: int, next_token: Optional[str] = None) -> json:\n",
    "    bearer_token = auth()\n",
    "    headers: dict[str, str] = create_headers(bearer_token)\n",
    "    json_obj_by_time_range: dict[str, dict] = dict()\n",
    "    max_results: int = 500\n",
    "    for i in range(0, len(start_times_list)):\n",
    "        total_count = 0\n",
    "        # Creates url and connects to endpoint then assignts the JSON STRING API response to json_response\n",
    "        url = create_full_search_url(keyword, start_times_list[i], end_times_list[i], max_results)\n",
    "        json_obj_response = connect_to_endpoint(url[0], headers, url[1], next_token) # prints response code\n",
    "        print(f\"Outer for loop enpoint called for list index {i} / {len(start_times_list) - 1}\")\n",
    "        json_obj_response.pop('includes', None)\n",
    "        json_obj_response['time'] = (f\"{start_times_list[i]} --- {end_times_list[i]}\")\n",
    "\n",
    "        # Appends the json object API response to the json_obj_data dictionary.\n",
    "        json_obj_by_time_range[f'time_range_{i}'] = json_obj_response\n",
    "        total_count += json_obj_response['meta']['result_count']\n",
    "        time.sleep(5)\n",
    "        \n",
    "        while total_count <= results_per_range:\n",
    "            if 'next_token' in json_obj_response['meta']:\n",
    "                next_token = json_obj_response['meta']['next_token']\n",
    "\n",
    "                # Creates url and connects to endpoint then assignts the JSON API response to json_response\n",
    "                #url = create_full_search_url(keyword, start_times_list[i], end_times_list[i], max_results)\n",
    "                json_obj_response = connect_to_endpoint(url[0], headers, url[1], next_token) # prints response code\n",
    "                print(f\"While loop enpoint called: index {i} / {len(start_times_list) - 1}\")\n",
    "                next_token = None\n",
    "                if 'data' in json_obj_response:\n",
    "                    json_obj_by_time_range[f'time_range_{i}']['data'].append(json_obj_response['data'])\n",
    "                    total_count += json_obj_response['meta']['result_count']\n",
    "                    print(f\"data key found and data appended: {total_count} / {results_per_range} tweets in this range scraped\")\n",
    "                else:\n",
    "                    print(\"empty next token\")\n",
    "            else:\n",
    "                print(\"No more tweets to scrape, total tweets will be less than amount desired.\")\n",
    "                print(f\"total results {total_count}\")\n",
    "                next_token = None\n",
    "                break\n",
    "            time.sleep(5)\n",
    "        time.sleep(5)\n",
    "    return(json_obj_by_time_range)\n",
    "        \n",
    "\n",
    "def return_user_ids_original_tweets():\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Endpoint Response Code: 200\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'original_tweet_user_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [165], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m                 tweet_metrics_dict[this_tweet_id] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     39\u001b[0m     \u001b[39mreturn\u001b[39;00m(tweet_metrics_dict)\n\u001b[0;32m---> 41\u001b[0m analyze_retweet_counts()\n\u001b[1;32m     43\u001b[0m json_response[\u001b[39m'\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m (\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mstart_time\u001b[39m}\u001b[39;00m\u001b[39m --- \u001b[39m\u001b[39m{\u001b[39;00mend_time\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     44\u001b[0m main_dict[\u001b[39m'\u001b[39m\u001b[39mtime_range_1\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m json_response\n",
      "Cell \u001b[0;32mIn [165], line 28\u001b[0m, in \u001b[0;36manalyze_retweet_counts\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mreferenced_tweets\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m json_response[\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m][i] \u001b[39mand\u001b[39;00m json_response[\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m][i][\u001b[39m'\u001b[39m\u001b[39mreferenced_tweets\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mretweeted\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     27\u001b[0m     original_tweet_id_from_retweet \u001b[39m=\u001b[39m json_response[\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m][i][\u001b[39m'\u001b[39m\u001b[39mreferenced_tweets\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> 28\u001b[0m     json_response[\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m][i][\u001b[39m'\u001b[39m\u001b[39moriginal_tweet_user_id\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m original_tweet_user_id\n\u001b[1;32m     29\u001b[0m     \u001b[39mif\u001b[39;00m original_tweet_id_from_retweet \u001b[39min\u001b[39;00m tweet_metrics_dict:\n\u001b[1;32m     30\u001b[0m         tweet_metrics_dict[original_tweet_id_from_retweet] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'original_tweet_user_id' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"WORKING EXAMPLE OF SO FAR, Above is for more function use etc.\"\"\"\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "bearer_token = auth()\n",
    "\"\"\"input the necessary inputs below.\"\"\"\n",
    "headers = create_headers(bearer_token)\n",
    "keyword = \"Smartchain OR Airdrop OR Crypto\"\n",
    "# Use the commented out code below when using full access api\n",
    "#start_time, end_time = random_date()\n",
    "start_time = \"2023-01-02T17:00:00Z\"\n",
    "end_time = \"2023-01-04T20:00:00Z\"\n",
    "\n",
    "max_results = 10\n",
    "url = create_full_search_url(keyword, start_time, end_time, max_results)\n",
    "json_response = connect_to_endpoint(url[0], headers, url[1])\n",
    "main_dict = dict()\n",
    "\"\"\"This function scrapes through a JSON data file from a twitter API call and adds the retweeted user id to the referenced_tweets key.\"\"\"\n",
    "def analyze_retweet_counts():\n",
    "    tweet_metrics_dict: dict = dict()\n",
    "    for i in range(0, len(json_response['data'])):\n",
    "        if 'referenced_tweets' in json_response['data'][i] and json_response['data'][i]['referenced_tweets'][0]['type'] == \"retweeted\":\n",
    "            original_tweet_id_from_retweet = json_response['data'][i]['referenced_tweets'][0]['id']\n",
    "            json_response['data'][i]['original_tweet_user_id'] = original_tweet_user_id\n",
    "            if original_tweet_id_from_retweet in tweet_metrics_dict:\n",
    "                tweet_metrics_dict[original_tweet_id_from_retweet] += 1\n",
    "            else:\n",
    "                tweet_metrics_dict[original_tweet_id_from_retweet] = 1\n",
    "        else:\n",
    "            this_tweet_id = json_response['data'][i]['id']\n",
    "            if this_tweet_id in tweet_metrics_dict:\n",
    "                tweet_metrics_dict[this_tweet_id] += 1\n",
    "            else:\n",
    "                tweet_metrics_dict[this_tweet_id] = 1\n",
    "    return(tweet_metrics_dict)\n",
    "\n",
    "analyze_retweet_counts()\n",
    "\n",
    "json_response['time'] = (f\"{start_time} --- {end_time}\")\n",
    "main_dict['time_range_1'] = json_response\n",
    "\n",
    "print(json.dumps(main_dict, indent=15))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Working Cell\n",
    "\n",
    "The below cell is intended to be the final cell which ties together all functions into the 'solution' to the protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2022-02-26T23:00:00Z', '2022-06-11T08:00:00Z']\n"
     ]
    }
   ],
   "source": [
    "start_list, end_list = return_n_random_hour_ranges_sorted(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Endpoint Response Code: 200\n",
      "Outer for loop enpoint called for list index 0 / 2\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 0 / 2\n",
      "data key found and data appended: 694 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 0 / 2\n",
      "data key found and data appended: 1036 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 0 / 2\n",
      "data key found and data appended: 1383 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 0 / 2\n",
      "data key found and data appended: 1721 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 0 / 2\n",
      "data key found and data appended: 2045 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 0 / 2\n",
      "data key found and data appended: 2400 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 0 / 2\n",
      "data key found and data appended: 2755 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 0 / 2\n",
      "data key found and data appended: 3087 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 0 / 2\n",
      "data key found and data appended: 3434 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 0 / 2\n",
      "data key found and data appended: 3795 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 0 / 2\n",
      "data key found and data appended: 4146 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 0 / 2\n",
      "data key found and data appended: 4504 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 0 / 2\n",
      "data key found and data appended: 4854 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 0 / 2\n",
      "data key found and data appended: 5197 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 0 / 2\n",
      "data key found and data appended: 5547 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 0 / 2\n",
      "data key found and data appended: 5908 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 0 / 2\n",
      "data key found and data appended: 6259 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 0 / 2\n",
      "data key found and data appended: 6613 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 0 / 2\n",
      "data key found and data appended: 6943 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 0 / 2\n",
      "data key found and data appended: 7268 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 0 / 2\n",
      "data key found and data appended: 7599 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 0 / 2\n",
      "data key found and data appended: 7915 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 0 / 2\n",
      "data key found and data appended: 8232 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 0 / 2\n",
      "data key found and data appended: 8565 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 0 / 2\n",
      "data key found and data appended: 8928 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 0 / 2\n",
      "data key found and data appended: 9287 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 0 / 2\n",
      "data key found and data appended: 9641 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 0 / 2\n",
      "data key found and data appended: 9970 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 0 / 2\n",
      "data key found and data appended: 10306 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "Outer for loop enpoint called for list index 1 / 2\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 1 / 2\n",
      "data key found and data appended: 693 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 1 / 2\n",
      "data key found and data appended: 1057 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 1 / 2\n",
      "data key found and data appended: 1395 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 1 / 2\n",
      "data key found and data appended: 1772 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 1 / 2\n",
      "data key found and data appended: 2122 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 1 / 2\n",
      "data key found and data appended: 2498 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 1 / 2\n",
      "data key found and data appended: 2842 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 1 / 2\n",
      "data key found and data appended: 3215 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 1 / 2\n",
      "data key found and data appended: 3577 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 1 / 2\n",
      "data key found and data appended: 3920 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 1 / 2\n",
      "data key found and data appended: 4287 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 1 / 2\n",
      "data key found and data appended: 4654 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 1 / 2\n",
      "data key found and data appended: 5019 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 1 / 2\n",
      "data key found and data appended: 5392 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 1 / 2\n",
      "data key found and data appended: 5751 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 1 / 2\n",
      "data key found and data appended: 6125 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 1 / 2\n",
      "data key found and data appended: 6483 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 1 / 2\n",
      "data key found and data appended: 6859 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 1 / 2\n",
      "data key found and data appended: 7245 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 1 / 2\n",
      "data key found and data appended: 7603 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 1 / 2\n",
      "data key found and data appended: 7946 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 1 / 2\n",
      "data key found and data appended: 8308 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 1 / 2\n",
      "data key found and data appended: 8681 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 1 / 2\n",
      "data key found and data appended: 9023 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 1 / 2\n",
      "data key found and data appended: 9398 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 1 / 2\n",
      "data key found and data appended: 9769 / 10000 tweets in this range scraped\n",
      "\n",
      "Endpoint Response Code: 200\n",
      "While loop enpoint called: index 1 / 2\n",
      "data key found and data appended: 10134 / 10000 tweets in this range scraped\n"
     ]
    }
   ],
   "source": [
    "#start_list = [\"2023-01-10T17:00:00Z\", \"2023-01-11T17:00:00Z\"] #\"2023-01-08T17:00:00Z\", \n",
    "#end_list = [\"2023-01-10T18:00:00Z\", \"2023-01-11T18:00:00Z\"] #\"2023-01-08T18:00:00Z\",\n",
    "\n",
    "json_final_data = tweets_per_range(\"Smartchain OR Airdrop OR Crypto OR Nft\", start_list, end_list, 10000)\n",
    "\n",
    "json_to_file = json.dumps(json_final_data)\n",
    "with open(\"data.json\", \"w\") as outfile:\n",
    "    outfile.write(json_to_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10134\n"
     ]
    }
   ],
   "source": [
    "f = open('data.json')\n",
    "\n",
    "data = json.load(f)\n",
    "  \n",
    "count = 0\n",
    "#print((data['time_range_1']['data'][300]))\n",
    "for key in data['time_range_1']['data']:\n",
    "    if len(key) > 20:\n",
    "        count+=len(key)\n",
    "    else:\n",
    "        count += 1\n",
    "print(count)\n",
    "#print(count)\n",
    "#print(json.dumps(data['time_range_1']['data'][360], indent = 4))\n",
    "#for item in data['time_range_0']['data']:\n",
    "    #print(len(item))\n",
    "#print(json.dumps(data['time_range_0']['data'][360], indent = 4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
