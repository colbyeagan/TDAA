{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First protocol\n",
    "_Progresses from top to botttom. Go to bottom and run all for proper use. Modify environment variables and queries as needed Markdown cells will_ _highlight functionality of following code cell. Functionality will be derived from the list below with the numbered list being referenced in other markdown cells._\n",
    "\n",
    "## Protocol\n",
    "· Start with keywords:\n",
    "\n",
    "- Smartchain\n",
    "\n",
    "- Nft\n",
    "\n",
    "- Airdrop\n",
    "\n",
    "- Crypto\n",
    "\n",
    "- …etc.\n",
    "\n",
    "1. Sample up to 10k tweets containing at least one term from 100 random hours from the past year (so 1M tweets)\n",
    "\n",
    "2. Determine the most engaged (top) with users from this combined sample (100 or 1000)\n",
    "\n",
    "3. Pull up to 1000 comments for each top user\n",
    "\n",
    "4. Determine top users whose comments mention at least three users other than the top user\n",
    "\n",
    "5. Expand top user sample if we don’t have at least 100 airdrop seeders\n",
    "\n",
    "6. Time series chart plots:\n",
    "\n",
    "7. Top user activity\n",
    "\n",
    "8. Airdrop seeder activity\n",
    "\n",
    "9. Negative reaction activity? (based on sentiment analysis of replies to airdrop messages)\n",
    "\n",
    "10. External crypto value signals (from where?)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies\n",
    "Run the following commands in the terminal to install the required packages\n",
    "\n",
    "$pip install requests  \n",
    "$pip install pandas  \n",
    "$pip install datetime  \n",
    "$pip install python-dateutil"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Authentication step\n",
    "In the code cell below replace bearer_token with your bearer token. Run the cell, then delete your bearer token.\n",
    "This creates the token as an environment variable to be used under the name TOKEN. The token can then be removed so that others do not have access to your token when code is shared via GitHub. The same could be achieved through a .env file and using .gitignore however this would require dotenv package which just makes things more complicaded yada yada just put your token in run the cell and delete it ok thank you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TOKEN'] = 'AAAAAAAAAAAAAAAAAAAAAAMwdgEAAAAA%2BBTpRVpy5ExIM6%2BgaytL9o0%2B63M%3Dt3GdaN5o2Hx03bp0XqrktMAotnw3wGHFH6Z3vYsNmtWbTPUxcF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAAAAAAAAAAAAAAAAAAAAAMwdgEAAAAA%2BBTpRVpy5ExIM6%2BgaytL9o0%2B63M%3Dt3GdaN5o2Hx03bp0XqrktMAotnw3wGHFH6Z3vYsNmtWbTPUxcF\n"
     ]
    }
   ],
   "source": [
    "\"\"\"This cell creates functions to be used for authentication as well as creating endpoints.\"\"\"\n",
    "import requests\n",
    "\n",
    "def auth():\n",
    "    \"\"\"Retrieves your bearer token.\"\"\"\n",
    "    return os.getenv('TOKEN')\n",
    "\n",
    "def create_headers(bearer_token):\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "\n",
    "\n",
    "def create_url(keyword, start_date, end_date, max_results = 10):\n",
    "    \n",
    "    #Change to the endpoint you want to collect data from\n",
    "    search_url = \"https://api.twitter.com/2/tweets/search/recent\" \n",
    "\n",
    "    #change params based on the endpoint you are using\n",
    "    query_params = {'query': keyword,\n",
    "                    'start_time': start_date,\n",
    "                    'end_time': end_date,\n",
    "                    'max_results': max_results,\n",
    "                    'expansions': 'author_id',\n",
    "                    'tweet.fields': 'id,text,author_id',\n",
    "                    #'user.fields': 'id,name,username,created_at',\n",
    "                    #'place.fields': 'country',\n",
    "                    'next_token': {}}\n",
    "    return (search_url, query_params)\n",
    "\n",
    "def connect_to_endpoint(url, headers, params, next_token = None):\n",
    "    params['next_token'] = next_token   #params object received from create_url function\n",
    "    response = requests.request(\"GET\", url, headers = headers, params = params)\n",
    "    print(\"Endpoint Response Code: \" + str(response.status_code))\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n",
    "\n",
    "print(auth())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import random\n",
    "\"\"\"This code cell contains two functions (is_leap_year and random_date) which help generate a random one hour date range when random_date() is called\"\"\"\n",
    "# Use by calling \"start_time, end_time = random_date()\"\n",
    "\n",
    "def is_leap_year(year):\n",
    "    \"\"\"Returns True if the given year is a leap year, False otherwise.\"\"\"\n",
    "    if year % 4 == 0:\n",
    "        if year % 100 == 0:\n",
    "            if year % 400 == 0:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        else:\n",
    "            return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def random_date():\n",
    "    \"\"\"Generate a random one hour date range within the last year in RFC 3339 format to be used with twitter API.\"\"\"\n",
    "    year = random.randint(datetime.datetime.now().year - 1, datetime.datetime.now().year)\n",
    "    month = random.randint(1, datetime.datetime.now().month)\n",
    "    if month == datetime.datetime.now().month:\n",
    "        day = random.randint(1, datetime.datetime.now().day)\n",
    "    elif month == 2:\n",
    "        if is_leap_year(year):\n",
    "            day = random.randint(1, 29)\n",
    "        else:\n",
    "            day = random.randint(1, 28)\n",
    "    elif month in [1, 3, 5, 7, 8, 10, 12]:\n",
    "        day = random.randint(1, 31)\n",
    "    else:\n",
    "        day = random.randint(1, 31)\n",
    "    hour = random.randint(0, 23)\n",
    "    start_time = datetime.datetime(year, month, day, hour)\n",
    "    end_time = start_time + datetime.timedelta(hours=1)\n",
    "    start_timestamp = start_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    end_timestamp = end_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    return start_timestamp, end_timestamp\n",
    "\n",
    "#start_time1, end_time1 = random_date()\n",
    "#print(f\"The one hour range is from {start_time1} to {end_time1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inputs for the request\n",
    "bearer_token = auth()\n",
    "headers = create_headers(bearer_token)\n",
    "keyword = \"Xbox lang:en\"\n",
    "# Choose a random one hour range within the last year\n",
    "#start_time, end_time = random_date()\n",
    "start_time = \"2022-12-29T17:00:00Z\"\n",
    "end_time = \"2022-12-31T20:00:00Z\"\n",
    "\n",
    "max_results = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Response Code: 200\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "url = create_url(keyword, start_time, end_time, max_results)\n",
    "json_response = connect_to_endpoint(url[0], headers, url[1])\n",
    "result_dict = json_response[\"data\"]\n",
    "#while \"next_token\" in json_response[\"meta\"] and len(result_dict) < 9900:\n",
    "    #print(json.dumps(json_response, indent=4, sort_keys=True))\n",
    "    #json_response = connect_to_endpoint(url[0], headers, url[1], json_response[\"meta\"][\"next_token\"])\n",
    "    #result_dict.extend(json_response[\"data\"])\n",
    "#print(json.dumps(json_response, indent=4, sort_keys=True))\n",
    "\n",
    "with open('data.json', 'w') as f:\n",
    "    json.dump(result_dict, f)\n",
    "\n",
    "df = pd.read_json('data.json')\n",
    "\n",
    "df.head()\n",
    "#url = create_url(keyword, start_time, end_time, max_results)\n",
    "#json_response = connect_to_endpoint(url[0], headers, url[1])\n",
    "#print(json.dumps(json_response, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inputs for tweets\n",
    "\n",
    "start_list = list()\n",
    "end_list = list()\n",
    "\n",
    "for _ in range(100):\n",
    "    start_time, end_time = random_date()\n",
    "    while start_time in start_list:\n",
    "        start_time, end_time = random_date()\n",
    "    start_list.append(start_time)\n",
    "    end_list.append(end_time)\n",
    "\n",
    "max_results = 500\n",
    "\n",
    "#Total number of tweets we collected from the loop\n",
    "total_tweets = 0\n",
    "\n",
    "# Create file\n",
    "csvFile = open(\"data.csv\", \"a\", newline=\"\", encoding='utf-8')\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "#Create headers for the data you want to save, in this example, we only want save these columns in our dataset\n",
    "csvWriter.writerow(['author id', 'created_at', 'geo', 'id','lang', 'like_count', 'quote_count', 'reply_count','retweet_count','source','tweet'])\n",
    "csvFile.close()\n",
    "\n",
    "for i in range(0,len(start_list)):\n",
    "\n",
    "    # Inputs\n",
    "    count = 0 # Counting tweets per time period\n",
    "    max_count = 100 # Max tweets per time period\n",
    "    flag = True\n",
    "    next_token = None\n",
    "    \n",
    "    # Check if flag is true\n",
    "    while flag:\n",
    "        # Check if max_count reached\n",
    "        if count >= max_count:\n",
    "            break\n",
    "        print(\"-------------------\")\n",
    "        print(\"Token: \", next_token)\n",
    "        url = create_url(keyword, start_list[i],end_list[i], max_results)\n",
    "        json_response = connect_to_endpoint(url[0], headers, url[1], next_token)\n",
    "        result_count = json_response['meta']['result_count']\n",
    "\n",
    "        if 'next_token' in json_response['meta']:\n",
    "            # Save the token to use for next call\n",
    "            next_token = json_response['meta']['next_token']\n",
    "            print(\"Next Token: \", next_token)\n",
    "            if result_count is not None and result_count > 0 and next_token is not None:\n",
    "                print(\"Start Date: \", start_list[i])\n",
    "                append_to_csv(json_response, \"data.csv\")\n",
    "                count += result_count\n",
    "                total_tweets += result_count\n",
    "                print(\"Total # of Tweets added: \", total_tweets)\n",
    "                print(\"-------------------\")\n",
    "                time.sleep(5)                \n",
    "        # If no next token exists\n",
    "        else:\n",
    "            if result_count is not None and result_count > 0:\n",
    "                print(\"-------------------\")\n",
    "                print(\"Start Date: \", start_list[i])\n",
    "                append_to_csv(json_response, \"data.csv\")\n",
    "                count += result_count\n",
    "                total_tweets += result_count\n",
    "                print(\"Total # of Tweets added: \", total_tweets)\n",
    "                print(\"-------------------\")\n",
    "                time.sleep(5)\n",
    "            \n",
    "            #Since this is the final request, turn flag to false to move to the next time period.\n",
    "            flag = False\n",
    "            next_token = None\n",
    "        time.sleep(5)\n",
    "print(\"Total number of results: \", total_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-01T07:00:00Z 2023-01-01T08:00:00Z\n",
      "0\n",
      "2022-01-02T00:00:00Z 2022-01-02T01:00:00Z\n",
      "1\n",
      "2023-01-02T00:00:00Z 2023-01-02T01:00:00Z\n",
      "2\n",
      "2022-01-01T17:00:00Z 2022-01-01T18:00:00Z\n",
      "3\n",
      "2023-01-02T10:00:00Z 2023-01-02T11:00:00Z\n",
      "4\n",
      "2023-01-01T20:00:00Z 2023-01-01T21:00:00Z\n",
      "5\n",
      "2023-01-01T04:00:00Z 2023-01-01T05:00:00Z\n",
      "6\n",
      "2022-01-02T21:00:00Z 2022-01-02T22:00:00Z\n",
      "7\n",
      "2022-01-02T17:00:00Z 2022-01-02T18:00:00Z\n",
      "8\n",
      "2023-01-01T16:00:00Z 2023-01-01T17:00:00Z\n",
      "9\n",
      "2022-01-02T12:00:00Z 2022-01-02T13:00:00Z\n",
      "10\n",
      "2022-01-01T21:00:00Z 2022-01-01T22:00:00Z\n",
      "11\n",
      "2022-01-02T14:00:00Z 2022-01-02T15:00:00Z\n",
      "12\n",
      "2022-01-02T11:00:00Z 2022-01-02T12:00:00Z\n",
      "13\n",
      "2022-01-02T21:00:00Z 2022-01-02T22:00:00Z\n",
      "14\n",
      "2022-01-01T03:00:00Z 2022-01-01T04:00:00Z\n",
      "15\n",
      "2022-01-01T12:00:00Z 2022-01-01T13:00:00Z\n",
      "16\n",
      "2022-01-01T18:00:00Z 2022-01-01T19:00:00Z\n",
      "17\n",
      "2023-01-02T02:00:00Z 2023-01-02T03:00:00Z\n",
      "18\n",
      "2022-01-02T03:00:00Z 2022-01-02T04:00:00Z\n",
      "19\n",
      "2023-01-02T22:00:00Z 2023-01-02T23:00:00Z\n",
      "20\n",
      "2022-01-01T03:00:00Z 2022-01-01T04:00:00Z\n",
      "21\n",
      "2022-01-02T12:00:00Z 2022-01-02T13:00:00Z\n",
      "22\n",
      "2023-01-02T08:00:00Z 2023-01-02T09:00:00Z\n",
      "23\n",
      "2022-01-02T13:00:00Z 2022-01-02T14:00:00Z\n",
      "24\n",
      "2023-01-01T17:00:00Z 2023-01-01T18:00:00Z\n",
      "25\n",
      "2023-01-01T00:00:00Z 2023-01-01T01:00:00Z\n",
      "26\n",
      "2022-01-02T08:00:00Z 2022-01-02T09:00:00Z\n",
      "27\n",
      "2022-01-01T07:00:00Z 2022-01-01T08:00:00Z\n",
      "28\n",
      "2022-01-02T06:00:00Z 2022-01-02T07:00:00Z\n",
      "29\n",
      "2023-01-02T02:00:00Z 2023-01-02T03:00:00Z\n",
      "30\n",
      "2022-01-02T05:00:00Z 2022-01-02T06:00:00Z\n",
      "31\n",
      "2023-01-02T00:00:00Z 2023-01-02T01:00:00Z\n",
      "32\n",
      "2022-01-01T12:00:00Z 2022-01-01T13:00:00Z\n",
      "33\n",
      "2022-01-02T19:00:00Z 2022-01-02T20:00:00Z\n",
      "34\n",
      "2023-01-01T08:00:00Z 2023-01-01T09:00:00Z\n",
      "35\n",
      "2022-01-02T07:00:00Z 2022-01-02T08:00:00Z\n",
      "36\n",
      "2023-01-01T04:00:00Z 2023-01-01T05:00:00Z\n",
      "37\n",
      "2022-01-01T15:00:00Z 2022-01-01T16:00:00Z\n",
      "38\n",
      "2022-01-01T13:00:00Z 2022-01-01T14:00:00Z\n",
      "39\n",
      "2023-01-01T23:00:00Z 2023-01-02T00:00:00Z\n",
      "40\n",
      "2022-01-02T04:00:00Z 2022-01-02T05:00:00Z\n",
      "41\n",
      "2022-01-01T19:00:00Z 2022-01-01T20:00:00Z\n",
      "42\n",
      "2022-01-01T17:00:00Z 2022-01-01T18:00:00Z\n",
      "43\n",
      "2023-01-01T14:00:00Z 2023-01-01T15:00:00Z\n",
      "44\n",
      "2023-01-02T00:00:00Z 2023-01-02T01:00:00Z\n",
      "45\n",
      "2022-01-02T19:00:00Z 2022-01-02T20:00:00Z\n",
      "46\n",
      "2022-01-01T20:00:00Z 2022-01-01T21:00:00Z\n",
      "47\n",
      "2023-01-01T22:00:00Z 2023-01-01T23:00:00Z\n",
      "48\n",
      "2023-01-02T20:00:00Z 2023-01-02T21:00:00Z\n",
      "49\n",
      "2022-01-02T14:00:00Z 2022-01-02T15:00:00Z\n",
      "50\n",
      "2022-01-02T10:00:00Z 2022-01-02T11:00:00Z\n",
      "51\n",
      "2023-01-01T05:00:00Z 2023-01-01T06:00:00Z\n",
      "52\n",
      "2022-01-01T13:00:00Z 2022-01-01T14:00:00Z\n",
      "53\n",
      "2023-01-02T21:00:00Z 2023-01-02T22:00:00Z\n",
      "54\n",
      "2022-01-02T16:00:00Z 2022-01-02T17:00:00Z\n",
      "55\n",
      "2022-01-02T16:00:00Z 2022-01-02T17:00:00Z\n",
      "56\n",
      "2022-01-02T10:00:00Z 2022-01-02T11:00:00Z\n",
      "57\n",
      "2022-01-02T22:00:00Z 2022-01-02T23:00:00Z\n",
      "58\n",
      "2022-01-01T13:00:00Z 2022-01-01T14:00:00Z\n",
      "59\n",
      "2022-01-02T03:00:00Z 2022-01-02T04:00:00Z\n",
      "60\n",
      "2022-01-02T01:00:00Z 2022-01-02T02:00:00Z\n",
      "61\n",
      "2022-01-01T15:00:00Z 2022-01-01T16:00:00Z\n",
      "62\n",
      "2023-01-02T20:00:00Z 2023-01-02T21:00:00Z\n",
      "63\n",
      "2022-01-02T13:00:00Z 2022-01-02T14:00:00Z\n",
      "64\n",
      "2022-01-02T16:00:00Z 2022-01-02T17:00:00Z\n",
      "65\n",
      "2022-01-02T07:00:00Z 2022-01-02T08:00:00Z\n",
      "66\n",
      "2022-01-01T14:00:00Z 2022-01-01T15:00:00Z\n",
      "67\n",
      "2023-01-02T01:00:00Z 2023-01-02T02:00:00Z\n",
      "68\n",
      "2022-01-02T03:00:00Z 2022-01-02T04:00:00Z\n",
      "69\n",
      "2022-01-02T10:00:00Z 2022-01-02T11:00:00Z\n",
      "70\n",
      "2023-01-02T06:00:00Z 2023-01-02T07:00:00Z\n",
      "71\n",
      "2022-01-01T22:00:00Z 2022-01-01T23:00:00Z\n",
      "72\n",
      "2022-01-02T20:00:00Z 2022-01-02T21:00:00Z\n",
      "73\n",
      "2023-01-02T03:00:00Z 2023-01-02T04:00:00Z\n",
      "74\n",
      "2023-01-01T18:00:00Z 2023-01-01T19:00:00Z\n",
      "75\n",
      "2023-01-02T06:00:00Z 2023-01-02T07:00:00Z\n",
      "76\n",
      "2022-01-02T06:00:00Z 2022-01-02T07:00:00Z\n",
      "77\n",
      "2022-01-02T12:00:00Z 2022-01-02T13:00:00Z\n",
      "78\n",
      "2023-01-01T02:00:00Z 2023-01-01T03:00:00Z\n",
      "79\n",
      "2022-01-02T19:00:00Z 2022-01-02T20:00:00Z\n",
      "80\n",
      "2022-01-01T08:00:00Z 2022-01-01T09:00:00Z\n",
      "81\n",
      "2023-01-01T00:00:00Z 2023-01-01T01:00:00Z\n",
      "82\n",
      "2023-01-02T06:00:00Z 2023-01-02T07:00:00Z\n",
      "83\n",
      "2023-01-01T21:00:00Z 2023-01-01T22:00:00Z\n",
      "84\n",
      "2023-01-01T00:00:00Z 2023-01-01T01:00:00Z\n",
      "85\n",
      "2022-01-01T23:00:00Z 2022-01-02T00:00:00Z\n",
      "86\n",
      "2022-01-02T07:00:00Z 2022-01-02T08:00:00Z\n",
      "87\n",
      "2022-01-02T04:00:00Z 2022-01-02T05:00:00Z\n",
      "88\n",
      "2023-01-01T16:00:00Z 2023-01-01T17:00:00Z\n",
      "89\n",
      "2023-01-02T02:00:00Z 2023-01-02T03:00:00Z\n",
      "90\n",
      "2023-01-01T09:00:00Z 2023-01-01T10:00:00Z\n",
      "91\n",
      "2023-01-01T10:00:00Z 2023-01-01T11:00:00Z\n",
      "92\n",
      "2023-01-02T21:00:00Z 2023-01-02T22:00:00Z\n",
      "93\n",
      "2022-01-01T03:00:00Z 2022-01-01T04:00:00Z\n",
      "94\n",
      "2022-01-02T00:00:00Z 2022-01-02T01:00:00Z\n",
      "95\n",
      "2023-01-01T10:00:00Z 2023-01-01T11:00:00Z\n",
      "96\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [51], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(_)\n\u001b[1;32m      7\u001b[0m \u001b[39mwhile\u001b[39;00m start_time \u001b[39min\u001b[39;00m start_list:\n\u001b[0;32m----> 8\u001b[0m     start_time, end_time \u001b[39m=\u001b[39m random_date()\n\u001b[1;32m      9\u001b[0m start_list\u001b[39m.\u001b[39mappend(start_time)\n\u001b[1;32m     10\u001b[0m end_list\u001b[39m.\u001b[39mappend(end_time)\n",
      "Cell \u001b[0;32mIn [45], line 24\u001b[0m, in \u001b[0;36mrandom_date\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m month \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39mrandint(\u001b[39m1\u001b[39m, datetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow()\u001b[39m.\u001b[39mmonth)\n\u001b[1;32m     23\u001b[0m \u001b[39mif\u001b[39;00m month \u001b[39m==\u001b[39m datetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow()\u001b[39m.\u001b[39mmonth:\n\u001b[0;32m---> 24\u001b[0m     day \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39;49mrandint(\u001b[39m1\u001b[39;49m, datetime\u001b[39m.\u001b[39;49mdatetime\u001b[39m.\u001b[39;49mnow()\u001b[39m.\u001b[39;49mday)\n\u001b[1;32m     25\u001b[0m \u001b[39melif\u001b[39;00m month \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m     26\u001b[0m     \u001b[39mif\u001b[39;00m is_leap_year(year):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/random.py:358\u001b[0m, in \u001b[0;36mRandom.randint\u001b[0;34m(self, a, b)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mempty range for randrange()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    356\u001b[0m     \u001b[39mreturn\u001b[39;00m istart \u001b[39m+\u001b[39m istep \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_randbelow(n)\n\u001b[0;32m--> 358\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrandint\u001b[39m(\u001b[39mself\u001b[39m, a, b):\n\u001b[1;32m    359\u001b[0m     \u001b[39m\"\"\"Return random integer in range [a, b], including both end points.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    362\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandrange(a, b\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_list = list()\n",
    "end_list = list()\n",
    "for _ in range(0, 100):\n",
    "    start_time, end_time = random_date()\n",
    "    print(start_time, end_time)\n",
    "    print(_)\n",
    "    while start_time in start_list:\n",
    "        start_time, end_time = random_date()\n",
    "    start_list.append(start_time)\n",
    "    end_list.append(end_time)\n",
    "\n",
    "print(start_list, end_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
