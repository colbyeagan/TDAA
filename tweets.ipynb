{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First protocol\n",
    "_Code written and runs in python 3.11.0. Modify environment variables and queries as needed._  \n",
    "_Please use venv_\n",
    "\n",
    "## Protocol\n",
    "· Start with keywords:\n",
    "\n",
    "- Smartchain\n",
    "\n",
    "- Nft\n",
    "\n",
    "- Airdrop\n",
    "\n",
    "- Crypto\n",
    "\n",
    "- …etc.\n",
    "\n",
    "1. Sample up to 10k tweets containing at least one term from 100 random hours from the past year (so 1M tweets)\n",
    "\n",
    "2. Determine the most engaged (top) with users from this combined sample (100 or 1000)\n",
    "\n",
    "3. Pull up to 1000 comments for each top user\n",
    "\n",
    "4. Determine top users whose comments mention at least three users other than the top user\n",
    "\n",
    "5. Expand top user sample if we don’t have at least 100 airdrop seeders\n",
    "\n",
    "6. Time series chart plots:\n",
    "\n",
    "7. Top user activity\n",
    "\n",
    "8. Airdrop seeder activity\n",
    "\n",
    "9. Negative reaction activity? (based on sentiment analysis of replies to airdrop messages)\n",
    "\n",
    "10. External crypto value signals (from where?)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies\n",
    "Run the following commands in the terminal to install the required packages\n",
    "\n",
    "$pip install requests  \n",
    "  \n",
    "$pip install pandas  \n",
    "  \n",
    "$pip install datetime  \n",
    "  \n",
    "$pip install python-dateutil\n",
    "  \n",
    "\n",
    "--------------------  \n",
    "create a files <data.json> in the same folder as this jupyter notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Authentication step\n",
    "In the code cell below replace bearer_token with your bearer token. Run the cell, then delete your bearer token.\n",
    "This creates the token as an environment variable to be used under the name TOKEN. The token can then be removed so that others do not have access to your token when code is shared via GitHub. I will change this to dotenv and a .gitignore file later I just havent done that yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TOKEN'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This cell creates functions to be used for authentication as well as creating endpoints.\"\"\"\n",
    "import requests\n",
    "\n",
    "def auth():\n",
    "    \"\"\"Retrieves your bearer token.\"\"\"\n",
    "    return os.getenv('TOKEN')\n",
    "\n",
    "def create_headers(bearer_token):\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "\n",
    "\n",
    "def create_url(keyword, start_date, end_date, max_results = 100):\n",
    "    \n",
    "    #Change to the endpoint you want to collect data from\n",
    "    search_url = \"https://api.twitter.com/2/tweets/search/all\" \n",
    "\n",
    "    #change params based on the endpoint you are using\n",
    "    query_params = {'query': keyword,\n",
    "                    'start_time': start_date,\n",
    "                    'end_time': end_date,\n",
    "                    'max_results': max_results,\n",
    "                    'expansions': 'author_id',\n",
    "                    'tweet.fields': 'id,created_at,text,author_id,public_metrics',\n",
    "                    'user.fields': 'id,name,username,created_at',\n",
    "                    #'place.fields': 'country',\n",
    "                    'next_token': {}}\n",
    "    return (search_url, query_params)\n",
    "\n",
    "def connect_to_endpoint(url, headers, params, next_token = None):\n",
    "    params['next_token'] = next_token   #params object received from create_url function\n",
    "    response = requests.request(\"GET\", url, headers = headers, params = params)\n",
    "    print(\"Endpoint Response Code: \" + str(response.status_code))\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n",
    "\n",
    "#print(auth())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import random\n",
    "\"\"\"This code cell contains two functions (is_leap_year and random_date) which help generate a random one hour date range when random_date() is called\"\"\"\n",
    "# Use by calling \"start_time, end_time = random_date()\"\n",
    "\n",
    "def is_leap_year(year):\n",
    "    \"\"\"Returns True if the given year is a leap year, False otherwise.\"\"\"\n",
    "    if year % 4 == 0:\n",
    "        if year % 100 == 0:\n",
    "            if year % 400 == 0:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        else:\n",
    "            return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def random_date():\n",
    "    \"\"\"Generate a random one hour date range within the last year in RFC 3339 format to be used with twitter API.\"\"\"\n",
    "    year = random.randint(datetime.datetime.now().year - 1, datetime.datetime.now().year)\n",
    "    month = random.randint(1, datetime.datetime.now().month)\n",
    "    if month == datetime.datetime.now().month:\n",
    "        day = random.randint(1, datetime.datetime.now().day - 1)\n",
    "    elif month == 2:\n",
    "        if is_leap_year(year):\n",
    "            day = random.randint(1, 29)\n",
    "        else:\n",
    "            day = random.randint(1, 28)\n",
    "    elif month in [1, 3, 5, 7, 8, 10, 12]:\n",
    "        day = random.randint(1, 31)\n",
    "    else:\n",
    "        day = random.randint(1, 31)\n",
    "    hour = random.randint(0, 23)\n",
    "    start_time = datetime.datetime(year, month, day, hour)\n",
    "    end_time = start_time + datetime.timedelta(hours=1)\n",
    "    start_timestamp = start_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    end_timestamp = end_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    return start_timestamp, end_timestamp\n",
    "\n",
    "#start_time1, end_time1 = random_date()\n",
    "#print(f\"The one hour range is from {start_time1} to {end_time1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"WORKING EXAMPLE OF SO FAR, Above is for more function use etc.\"\"\"\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "from typing import Optional\n",
    "import time\n",
    "\n",
    "def tweets_per_range(keyword: str, start_times_list: list, end_times_list: list, results_per_range: int, next_token: Optional[str] = None) -> json:\n",
    "    bearer_token = auth()\n",
    "    headers = create_headers(bearer_token)\n",
    "    json_data = []\n",
    "    for i in range(0, len(start_times_list)):\n",
    "        total_count = 0\n",
    "        max_results = 100\n",
    "        url = create_url(keyword, start_times_list[i], end_times_list[i], max_results)\n",
    "        json_response = connect_to_endpoint(url[0], headers, url[1], next_token)\n",
    "        json_data.append(json_response[\"data\"])\n",
    "        total_count += json_response['meta']['result_count']\n",
    "        #if (total_count <= results_per_range) and (if 'next_token' in json_response['meta']):\n",
    "            #next_token_st = json_response['meta']['next_token']\n",
    "            #tweets_per_range(keyword: , start_times_list[i], end__times_list[i], results_per_range, next_token_st)\n",
    "\n",
    "    while total_count <= results_per_range:\n",
    "        if 'next_token' in json_response['meta']:\n",
    "            next_token = json_response['meta']['next_token']\n",
    "            url = create_url(keyword, start_times_list[i], end_times_list[i], max_results)\n",
    "            json_response = connect_to_endpoint(url[0], headers, url[1], next_token)\n",
    "            json_data.append(json_response['data'])\n",
    "            total_count += json_response['meta']['result_count']\n",
    "            time.sleep(5)\n",
    "        else:\n",
    "            print(\"Max results reached before desired amount of tweets.\")\n",
    "            break\n",
    "    return(json_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Working Cell\n",
    "\n",
    "The below cell is intended to be the final cell which ties together all functions into the 'solution' to the protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the commented out code below when using full access api\n",
    "# #start_time, end_time = random_date()\n",
    "start_list = [\"2023-01-08T17:00:00Z\", \"2023-01-10T17:00:00Z\", \"2023-01-11T17:00:00Z\"]\n",
    "end_list = [\"2023-01-08T18:00:00Z\", \"2023-01-10T18:00:00Z\", \"2023-01-11T18:00:00Z\"]\n",
    "\n",
    "json_final_data = tweets_per_range(\"Smartchain OR Airdrop OR Crypto OR Nft\", start_list, end_list, 200)\n",
    "\n",
    "json_to_file = json.dumps(json_final_data, indent=4)\n",
    "with open(\"data.json\", \"w\") as outfile:\n",
    "    outfile.write(json_to_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
